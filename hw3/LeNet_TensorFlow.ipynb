{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MMcWUHT5-eVD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fEvJTxr2C55-"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5CqAuLuDC94",
    "outputId": "c082e3c5-58a4-4577-c6a6-cab6a46406ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XizrWVlmY1NQ",
    "outputId": "79110c67-65e5-46cf-c7ef-12f743e14476"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([Dimension(60000), Dimension(32), Dimension(32)])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n",
    "x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hy_dVa44ZOLk",
    "outputId": "27409e22-03ac-46a9-b388-8f832fcdcc42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([Dimension(60000), Dimension(32), Dimension(32), Dimension(1)])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = tf.expand_dims(x_train, axis=3, name=None)\n",
    "x_test = tf.expand_dims(x_test, axis=3, name=None)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gJuMl9GAnoM5"
   },
   "outputs": [],
   "source": [
    "x_val = x_train[-2000:,:,:,:]\n",
    "y_val = y_train[-2000:]\n",
    "x_train = x_train[:-2000,:,:,:]\n",
    "y_train = y_train[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeaLkOM-XRZA",
    "outputId": "38661b63-7ded-4ac8-ce7f-a8c007fa41ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6, 5, activation='tanh', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.AveragePooling2D(2))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(16, 5, activation='tanh'))\n",
    "model.add(layers.AveragePooling2D(2))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(120, 5, activation='tanh'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(84, activation='tanh'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pOAJW5ByhYCl"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xv-ml2R6hw_V",
    "outputId": "216079d9-5316-457b-fff7-07052aa09efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[58000,16,5,5] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/average_pooling2d_1/AvgPool_grad/AvgPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-7bba8d621438>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[0;32m    878\u001B[0m           \u001B[0minitial_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minitial_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    879\u001B[0m           \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 880\u001B[1;33m           validation_steps=validation_steps)\n\u001B[0m\u001B[0;32m    881\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    882\u001B[0m   def evaluate(self,\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001B[0m in \u001B[0;36mmodel_iteration\u001B[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001B[0m\n\u001B[0;32m    264\u001B[0m           \u001B[1;31m# `ins` can be callable in DistributionStrategy + eager case.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    265\u001B[0m           \u001B[0mactual_inputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mins\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mins\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 266\u001B[1;33m           \u001B[0mbatch_outs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mactual_inputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    267\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOutOfRangeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    268\u001B[0m           logging.warning('Your dataset iterator ran out of data; '\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   3074\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3075\u001B[0m     fetched = self._callable_fn(*array_vals,\n\u001B[1;32m-> 3076\u001B[1;33m                                 run_metadata=self.run_metadata)\n\u001B[0m\u001B[0;32m   3077\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_fetch_callbacks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfetched\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fetches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3078\u001B[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1437\u001B[0m           ret = tf_session.TF_SessionRunCallable(\n\u001B[0;32m   1438\u001B[0m               \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_session\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1439\u001B[1;33m               run_metadata_ptr)\n\u001B[0m\u001B[0;32m   1440\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1441\u001B[0m           \u001B[0mproto_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001B[0m in \u001B[0;36m__exit__\u001B[1;34m(self, type_arg, value_arg, traceback_arg)\u001B[0m\n\u001B[0;32m    526\u001B[0m             \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    527\u001B[0m             \u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mc_api\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_Message\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstatus\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstatus\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 528\u001B[1;33m             c_api.TF_GetCode(self.status.status))\n\u001B[0m\u001B[0;32m    529\u001B[0m     \u001B[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    530\u001B[0m     \u001B[1;31m# as there is a reference to status from this from the traceback due to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: OOM when allocating tensor with shape[58000,16,5,5] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/average_pooling2d_1/AvgPool_grad/AvgPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64,steps_per_epoch=1, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "id": "AfX0d7zyocFw",
    "outputId": "b92f5a88-5045-4941-9616-a812f6a7480f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-c153e87fc787>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msubplots\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfigsize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0maxs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'loss'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0maxs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'val_loss'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0maxs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Training Loss vs Validation Loss'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1080x1080 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].plot(history.history['val_loss'])\n",
    "axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "axs[0].legend(['Train', 'Val'])\n",
    "\n",
    "axs[1].plot(history.history['accuracy'])\n",
    "axs[1].plot(history.history['val_accuracy'])\n",
    "axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "axs[1].legend(['Train', 'Val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLQqDljamZTV",
    "outputId": "4d65a32a-5fec-4b85-8aab-5a26fedd9166"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using data tensors as input to a model, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-11-db23ef76f2a6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m    987\u001B[0m         \u001B[0mcheck_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    988\u001B[0m         \u001B[0msteps_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'steps'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 989\u001B[1;33m         steps=steps)\n\u001B[0m\u001B[0;32m    990\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    991\u001B[0m     if (self.run_eagerly or (isinstance(x, iterator_ops.EagerIterator) and\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_standardize_user_data\u001B[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001B[0m\n\u001B[0;32m   2202\u001B[0m     \u001B[1;31m# Validates `steps` argument based on x's type.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2203\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcheck_steps\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2204\u001B[1;33m       \u001B[0mtraining_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_steps_argument\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msteps\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msteps_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2205\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2206\u001B[0m     \u001B[0mis_x_eager_iterator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miterator_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mEagerIterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001B[0m in \u001B[0;36mcheck_steps_argument\u001B[1;34m(input_data, steps, steps_name)\u001B[0m\n\u001B[0;32m    958\u001B[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001B[0;32m    959\u001B[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001B[1;32m--> 960\u001B[1;33m                            input_type=input_type_str, steps_name=steps_name))\n\u001B[0m\u001B[0;32m    961\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    962\u001B[0m   \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: When using data tensors as input to a model, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LeNet_TensorFlow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}